# Fetch MCP Implementation Plan

## Overview

**Package**: `@modelcontextprotocol/server-fetch`  
**Type**: stdio  
**Priority**: Medium (Tier 2)  
**Complexity**: ⭐ Easy

The Fetch MCP provides HTTP request capabilities within VS Code, enabling AI to fetch web content, validate APIs, check RSS feeds, and download resources - all essential for content validation and research.

---

## Installation & Configuration

### Step 1: Add to mcp.json

```jsonc
{
  "servers": {
    // ... existing servers ...
    "Fetch": {
      "command": "npx",
      "args": [
        "-y",
        "@modelcontextprotocol/server-fetch"
      ],
      "type": "stdio",
      "disabled": false
    }
  }
}
```

**Note**: No additional configuration needed - works out of the box!

### Step 2: Restart VS Code

After adding the configuration, restart VS Code to load the new MCP server.

### Step 3: Verify Installation

Ask Copilot: "Fetch the content from https://nextjs.org and summarize the homepage"

---

## Security Considerations

### Allowed Operations

The Fetch MCP can:
- ✅ Make GET requests to public URLs
- ✅ Fetch HTML, JSON, XML, and text content
- ✅ Follow redirects
- ✅ Handle different content types

### Restrictions

The Fetch MCP should NOT:
- ❌ Access localhost or internal networks (security risk)
- ❌ Make POST/PUT/DELETE requests (read-only by design)
- ❌ Access authenticated endpoints (no credential storage)
- ❌ Download large files (may timeout)

---

## Use Cases for This Project

### 1. Content Research & Validation

**Fetch Competitor Content**
```
Prompt: "Fetch https://vercel.com/blog and show me their latest post titles"
```

**Expected Result**:
- HTML content parsed
- Post titles extracted
- Helps research competitor strategy

**Validate External Links**
```
Prompt: "Check if all external links in my latest blog post are still working"
```

**Expected Result**:
- Tests each link
- Reports broken links
- Suggests fixes

### 2. RSS Feed Management

**Check Your Own Feeds**
```
Prompt: "Fetch https://cyberdrew.dev/rss.xml and validate the feed structure"
```

**Expected Result**:
- Verifies RSS is valid XML
- Checks all required fields
- Ensures feed is working

**Monitor Competitor Feeds**
```
Prompt: "Fetch https://competitor.com/rss.xml and show me their latest 5 posts"
```

**Expected Result**:
- Latest post titles and dates
- Topic inspiration
- Competitive intelligence

### 3. API Documentation Validation

**Check API Endpoints**
```
Prompt: "Fetch https://api.github.com/users/dcyfr and show the public profile data"
```

**Expected Result**:
- JSON response
- Validates API is working
- Helps write API integration docs

**Validate API Examples**
```
Prompt: "Fetch the example from the GitHub API docs and verify it works"
```

**Expected Result**:
- Tests real API responses
- Ensures documentation is accurate
- Catches breaking changes

### 4. Content Aggregation

**Fetch Documentation**
```
Prompt: "Fetch the Next.js App Router documentation page and extract key sections"
```

**Expected Result**:
- Current documentation content
- Key topics and examples
- Reference for blog posts

**Download Reference Materials**
```
Prompt: "Fetch the MDX specification from their website"
```

**Expected Result**:
- Full specification text
- Authoritative reference
- Accurate citation source

### 5. Link Validation & SEO

**Validate Internal Links**
```
Prompt: "Check if /blog/my-old-post still exists"
```

**Expected Result**:
- HTTP status code
- Identifies broken links
- Helps maintain SEO

**Check Canonical URLs**
```
Prompt: "Fetch my blog post and verify the canonical URL is correct"
```

**Expected Result**:
- Validates meta tags
- Ensures proper SEO setup
- Catches configuration errors

---

## Integration with Existing Workflow

### With Blog System

**Pre-Publication Checks**:
```
1. "Fetch all external links in this post"
2. "Verify each link returns 200 OK"
3. "Report any broken links"
```

**Post-Publication Validation**:
```
1. "Fetch https://cyberdrew.dev/blog/my-new-post"
2. "Verify it loads successfully"
3. "Check meta tags and OG images"
```

### With RSS Feeds

**Feed Testing**:
```
1. "Fetch /rss.xml and /atom.xml"
2. "Validate feed structure"
3. "Ensure all posts are included"
```

**Feed Comparison**:
```
1. "Fetch my RSS feed"
2. "Compare with production feed"
3. "Identify any differences"
```

### With GitHub Integration

**Validate GitHub Links**:
```
1. "Fetch my GitHub profile API"
2. "Verify contribution data is accessible"
3. "Test heatmap data endpoint"
```

---

## Example Commands for This Project

### Content Validation
- "Fetch my latest blog post and check if all images load"
- "Verify all external links in /blog are working"
- "Check if my RSS feed is valid XML"

### API Testing
- "Fetch the GitHub API for my profile"
- "Test the Vercel deployment API endpoint"
- "Verify the Inngest event endpoint is accessible"

### Competitive Research
- "Fetch https://competitor.com/blog and analyze their content"
- "Get the latest posts from relevant RSS feeds"
- "Check what topics are trending on tech blogs"

### Documentation Validation
- "Fetch the official Next.js docs for App Router"
- "Get the latest React documentation for hooks"
- "Download the MDX specification for reference"

### SEO Checks
- "Fetch my homepage and verify meta tags"
- "Check Open Graph images are loading"
- "Validate canonical URLs across all pages"

---

## Advanced Use Cases

### 1. Automated Link Checking

Create a workflow to check all blog links:
```
Prompt: "For each blog post:
1. Extract all external links
2. Fetch each link
3. Report any that return 404 or error
4. Create a report in /docs/maintenance/broken-links.md"
```

### 2. RSS Feed Monitoring

Daily check for new content:
```
Prompt: "Fetch these RSS feeds:
- Vercel blog
- Next.js blog
- React blog
Then summarize any posts from the last 24 hours"
```

### 3. API Health Monitoring

Validate third-party integrations:
```
Prompt: "Fetch these APIs and report status:
- GitHub API
- Vercel API
- Sentry status page"
```

### 4. Content Scraping (Ethical)

Research public content:
```
Prompt: "Fetch top 5 articles about Next.js 16 and extract:
- Main topics covered
- Code examples used
- Common patterns"
```

### 5. Sitemap Validation

Ensure all pages are accessible:
```
Prompt: "Fetch /sitemap.xml and verify each URL returns 200"
```

---

## Best Practices

### ✅ Do's

- ✅ **Use for public content**: Only fetch publicly accessible URLs
- ✅ **Respect robots.txt**: Don't fetch pages marked as disallowed
- ✅ **Handle errors gracefully**: Expect some requests to fail
- ✅ **Cache results**: Don't repeatedly fetch the same URL
- ✅ **Be considerate**: Don't hammer servers with requests

### ❌ Don'ts

- ❌ **Don't fetch private content**: No authenticated endpoints
- ❌ **Don't scrape aggressively**: Be respectful of rate limits
- ❌ **Don't store sensitive data**: No credentials in URLs
- ❌ **Don't download large files**: Keep requests reasonable
- ❌ **Don't violate ToS**: Respect website terms of service

---

## Troubleshooting

### "Connection refused" Error

**Cause**: URL is not accessible or localhost

**Solution**:
- Verify URL is public
- Check for typos in URL
- Ensure site is online

### "Timeout" Error

**Cause**: Server too slow or large file

**Solution**:
- Try a different URL
- Fetch smaller resources
- Check your internet connection

### "Invalid URL" Error

**Cause**: Malformed URL

**Solution**:
- Ensure URL includes protocol: `https://`
- Check for spaces or special characters
- Validate URL format

### "403 Forbidden" Error

**Cause**: Server blocking requests

**Solution**:
- Site may require authentication
- May have bot protection
- Try different approach (e.g., official API)

---

## Performance Considerations

### Request Timing

- **Typical request**: 100-500ms
- **Slow servers**: 1-5 seconds
- **Timeout**: 30 seconds (default)

### Rate Limiting

**Self-imposed limits**:
- Max 10 requests per minute per domain
- Wait 1 second between requests to same domain
- Don't make parallel requests to same server

### Content Size

**Optimal sizes**:
- HTML pages: < 500KB
- JSON responses: < 100KB
- RSS feeds: < 200KB

**Avoid**:
- Large files (> 1MB)
- Video/audio content
- Binary downloads

---

## Integration with Other MCPs

### With Memory MCP
```
Workflow:
1. "Fetch competitor blog posts"
2. "Remember their content topics"
3. "Identify content gaps for our blog"
```

### With Filesystem MCP
```
Workflow:
1. "Fetch latest React docs"
2. "Save summary to /docs/reference/react-19.md"
3. "Update our blog post with latest info"
```

---

## Testing the Implementation

### Test 1: Basic Fetch
```
Prompt: "Fetch https://jsonplaceholder.typicode.com/posts/1"
Expected: JSON object with post data
```

### Test 2: HTML Parsing
```
Prompt: "Fetch https://example.com and show me the page title"
Expected: "Example Domain"
```

### Test 3: RSS Feed
```
Prompt: "Fetch https://cyberdrew.dev/rss.xml and show the first item"
Expected: Your latest blog post from RSS
```

### Test 4: Error Handling
```
Prompt: "Fetch https://httpstat.us/404"
Expected: Graceful handling of 404 error
```

---

## Common Patterns

### Pattern 1: Link Validation Script

```
Workflow for blog post validation:
1. Read blog post MDX file
2. Extract all [text](url) style links
3. Fetch each URL
4. Report status (200 OK, 404 Not Found, etc.)
5. List any broken links
```

### Pattern 2: RSS Feed Monitoring

```
Daily content check:
1. Fetch competitor RSS feeds
2. Extract post titles and dates
3. Compare with yesterday's fetch (from Memory MCP)
4. Report new posts
5. Identify trending topics
```

### Pattern 3: API Integration Testing

```
Before deploying API changes:
1. Fetch API endpoint
2. Verify response structure
3. Check all required fields present
4. Validate data types
5. Report any issues
```

### Pattern 4: Documentation Sync

```
Weekly documentation check:
1. Fetch official library docs
2. Compare with our blog references
3. Identify outdated information
4. Create update list
5. Update blog posts
```

---

## Security Best Practices

### URL Validation

Always validate URLs before fetching:
```
✅ Good: https://api.github.com/users/dcyfr
✅ Good: https://nextjs.org/docs
❌ Bad: http://localhost:3000
❌ Bad: file:///etc/passwd
❌ Bad: Internal network IPs
```

### Content Handling

Be careful with fetched content:
- Don't execute code from fetched content
- Validate JSON before processing
- Sanitize HTML before displaying
- Don't store credentials found in responses

### Privacy

Respect user privacy:
- Don't fetch user-specific pages
- Don't bypass paywalls
- Don't access authenticated content
- Don't violate website ToS

---

## Maintenance

### Regular Checks

**Weekly**:
- Verify your RSS feeds are accessible
- Check your sitemap URLs are valid
- Test API endpoints still work

**Monthly**:
- Audit external links in blog posts
- Update broken or moved links
- Remove dead links

**Quarterly**:
- Review fetch usage patterns
- Optimize common fetch operations
- Update fetch error handling

---

## Next Steps After Implementation

1. **Test basic fetching** with public URLs
2. **Validate your RSS feeds** are working correctly
3. **Create link checking workflow** for blog posts
4. **Set up RSS monitoring** for competitor content
5. **Integrate with other MCPs** for enhanced workflows

---

## Related Documentation

- [MCP Servers Overview](../servers.md)
- [Blog System Architecture](../../blog/architecture.md)
- [RSS Feed Documentation](../../rss/feeds.md)
- [API Routes Overview](../../api/routes/overview.md)

---

**Status**: Ready to implement  
**Estimated Setup Time**: 5 minutes  
**Monthly Cost**: $0 (no external services)  
**Estimated ROI**: Medium - useful for validation and research, complements other MCPs
